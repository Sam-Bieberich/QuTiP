{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74361088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:30.431654Z",
     "iopub.status.busy": "2025-07-16T18:54:30.431452Z",
     "iopub.status.idle": "2025-07-16T18:54:31.464372Z",
     "shell.execute_reply": "2025-07-16T18:54:31.463848Z",
     "shell.execute_reply.started": "2025-07-16T18:54:30.431631Z"
    }
   },
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "import scqubits as scq\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import warnings\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de53d47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.465077Z",
     "iopub.status.busy": "2025-07-16T18:54:31.464869Z",
     "iopub.status.idle": "2025-07-16T18:54:31.467994Z",
     "shell.execute_reply": "2025-07-16T18:54:31.467401Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.465062Z"
    }
   },
   "outputs": [],
   "source": [
    "levels = 6\n",
    "fluxonium = scq.Fluxonium(EJ=8.9, EC=2.5, EL=0.5, flux=0.48, cutoff=110)\n",
    "c_ops = None  # will be initialized once below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632fd063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.470048Z",
     "iopub.status.busy": "2025-07-16T18:54:31.469780Z",
     "iopub.status.idle": "2025-07-16T18:54:31.475019Z",
     "shell.execute_reply": "2025-07-16T18:54:31.474577Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.470025Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_c_ops():\n",
    "    gamma_ij = {}\n",
    "    for j in range(1, levels):\n",
    "        for i in range(j):\n",
    "            t1 = fluxonium.t1_capacitive(j, i, Q_cap=1e5)\n",
    "            if t1 is not None and t1 > 0:\n",
    "                rate = 1.0 / t1\n",
    "                gamma_ij[(i, j)] = rate\n",
    "                gamma_ij[(j, i)] = rate\n",
    "    c_ops_local = []\n",
    "    for (i, j), gamma in gamma_ij.items():\n",
    "        cop = np.sqrt(gamma) * qt.basis(levels, i) * qt.basis(levels, j).dag()\n",
    "        c_ops_local.append(cop)\n",
    "    return c_ops_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd0614e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.477337Z",
     "iopub.status.busy": "2025-07-16T18:54:31.477172Z",
     "iopub.status.idle": "2025-07-16T18:54:31.481967Z",
     "shell.execute_reply": "2025-07-16T18:54:31.481445Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.477322Z"
    }
   },
   "outputs": [],
   "source": [
    "def evolve(omega_d, t_g):\n",
    "    global c_ops\n",
    "    if c_ops is None:\n",
    "        c_ops = init_c_ops()\n",
    "\n",
    "    evals, evecs = fluxonium.eigensys(evals_count=levels)\n",
    "    n_op_energy_basis = qt.Qobj(fluxonium.process_op(fluxonium.n_operator(), energy_esys=(evals, evecs)))\n",
    "    H0 = qt.Qobj(np.diag(evals))\n",
    "    A = 0.1\n",
    "    drive_op = n_op_energy_basis\n",
    "    H = [H0, [A * drive_op, 'cos(wd * t)']]\n",
    "    args = {'wd': omega_d}\n",
    "    options = qt.Options(nsteps=1000000, store_states=True, atol=1e-10, rtol=1e-9)\n",
    "\n",
    "    propagator = qt.propagator(H, t_g, args=args, options=options, c_ops=c_ops)\n",
    "    propagator_kraus = qt.to_kraus(propagator)\n",
    "    propagator_2x2 = [qt.Qobj(k.full()[:2, :2]) for k in propagator_kraus]\n",
    "    p_2x2_super = qt.kraus_to_super(propagator_2x2)\n",
    "    fidelity = qt.average_gate_fidelity(p_2x2_super, qt.sigmax())\n",
    "    print(\"completed iteration\")\n",
    "    return fidelity\n",
    "\n",
    "def wrapped_evolve(args):\n",
    "    return evolve(*args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061cafb",
   "metadata": {},
   "source": [
    "## Serial Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a52c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.484369Z",
     "iopub.status.busy": "2025-07-16T18:54:31.484126Z",
     "iopub.status.idle": "2025-07-16T18:54:31.488425Z",
     "shell.execute_reply": "2025-07-16T18:54:31.487731Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.484345Z"
    }
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     evals, _ = fluxonium.eigensys(evals_count=levels)\n",
    "#     omega_d_base = evals[1] - evals[0]\n",
    "\n",
    "#     omega_d_array = np.linspace(omega_d_base - 0.005, omega_d_base + 0.005, 10)\n",
    "#     peak_time_noise = 559.5559555955596  # previously determined\n",
    "#     t_g_array = np.linspace(0.99 * peak_time_noise, 1.01 * peak_time_noise, 10)\n",
    "#     param_pairs = list(itertools.product(omega_d_array, t_g_array))\n",
    "#     print(f\"Total simulations to run: {len(param_pairs)}\")\n",
    "\n",
    "#     results_flat = []\n",
    "#     for (omega_d, t_g) in param_pairs:\n",
    "#         print(f\"Running: omega_d={omega_d:.5f}, t_g={t_g:.2f}\")\n",
    "#         fidelity = evolve(omega_d, t_g)\n",
    "#         results_flat.append(fidelity)\n",
    "\n",
    "#     results = np.reshape(results_flat, (len(omega_d_array), len(t_g_array)))\n",
    "\n",
    "#     max_idx = np.unravel_index(np.argmax(results), results.shape)\n",
    "#     max_value = results[max_idx]\n",
    "#     omega_d_best = omega_d_array[max_idx[0]]\n",
    "#     t_g_best = t_g_array[max_idx[1]]\n",
    "\n",
    "#     print(\"\\n=== Final Results ===\")\n",
    "#     print(f\"Best fidelity: {max_value}\")\n",
    "#     print(f\"Found at omega_d = {omega_d_best}, t_g = {t_g_best}\")\n",
    "#     print(f\"Indices in results array: {max_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bd3aa",
   "metadata": {},
   "source": [
    "## Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e233c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.489653Z",
     "iopub.status.busy": "2025-07-16T18:54:31.489388Z",
     "iopub.status.idle": "2025-07-16T18:54:31.510209Z",
     "shell.execute_reply": "2025-07-16T18:54:31.509726Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.489629Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm  # Better in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfaa065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.511195Z",
     "iopub.status.busy": "2025-07-16T18:54:31.510946Z",
     "iopub.status.idle": "2025-07-16T18:54:31.514320Z",
     "shell.execute_reply": "2025-07-16T18:54:31.513917Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.511173Z"
    }
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     evals, _ = fluxonium.eigensys(evals_count=levels)\n",
    "#     omega_d_base = evals[1] - evals[0]\n",
    "\n",
    "#     omega_d_array = np.linspace(omega_d_base - 0.005, omega_d_base + 0.005, 10)\n",
    "#     peak_time_noise = 559.5559555955596  \n",
    "#     t_g_array = np.linspace(0.99 * peak_time_noise, 1.01 * peak_time_noise, 10)\n",
    "#     param_pairs = list(itertools.product(omega_d_array, t_g_array))\n",
    "#     print(f\"Total simulations to run: {len(param_pairs)}\")\n",
    "\n",
    "#     # Parallel execution using joblib\n",
    "#     results_flat = Parallel(n_jobs=-1)(\n",
    "#         delayed(evolve)(omega_d, t_g)\n",
    "#         for (omega_d, t_g) in tqdm(param_pairs, desc=\"Running simulations\")\n",
    "#     )\n",
    "\n",
    "#     results = np.reshape(results_flat, (len(omega_d_array), len(t_g_array)))\n",
    "\n",
    "#     max_idx = np.unravel_index(np.argmax(results), results.shape)\n",
    "#     max_value = results[max_idx]\n",
    "#     omega_d_best = omega_d_array[max_idx[0]]\n",
    "#     t_g_best = t_g_array[max_idx[1]]\n",
    "\n",
    "#     print(\"\\n=== Final Results ===\")\n",
    "#     print(f\"Best fidelity: {max_value}\")\n",
    "#     print(f\"Found at omega_d = {omega_d_best}, t_g = {t_g_best}\")\n",
    "#     print(f\"Indices in results array: {max_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561b0156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.515509Z",
     "iopub.status.busy": "2025-07-16T18:54:31.515265Z",
     "iopub.status.idle": "2025-07-16T18:54:31.519874Z",
     "shell.execute_reply": "2025-07-16T18:54:31.519025Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.515487Z"
    }
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902547f",
   "metadata": {},
   "source": [
    "### Param map rework for windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec28d0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.520923Z",
     "iopub.status.busy": "2025-07-16T18:54:31.520691Z",
     "iopub.status.idle": "2025-07-16T18:54:31.538341Z",
     "shell.execute_reply": "2025-07-16T18:54:31.537774Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.520906Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_map_qutip(task, values, task_args=tuple(), task_kwargs={}, **kwargs):\n",
    "    os.environ[\"QUTIP_IN_PARALLEL\"] = \"TRUE\"\n",
    "    kw = _default_kwargs()\n",
    "    if \"num_cpus\" in kwargs:\n",
    "        kw[\"num_cpus\"] = kwargs[\"num_cpus\"]\n",
    "\n",
    "    nfinished = [0]\n",
    "\n",
    "    try:\n",
    "        pool = mp.Pool(processes=kw[\"num_cpus\"])\n",
    "\n",
    "        async_res = [\n",
    "            pool.apply_async(\n",
    "                task, (value,) + task_args, task_kwargs\n",
    "            )\n",
    "            for value in values\n",
    "        ]\n",
    "\n",
    " \n",
    "\n",
    "        # while not all([ar.ready() for ar in async_res]):\n",
    "        #     for ar in async_res:\n",
    "        #         ar.wait(timeout=0.1)\n",
    "        start_time = time.time()\n",
    "        timeout_sec = 60  # 1 minute timeout for debugging\n",
    "        while not all([ar.ready() for ar in async_res]):\n",
    "            print(f\"{sum(ar.ready() for ar in async_res)}/{len(async_res)} tasks completed...\")\n",
    "            time.sleep(1)\n",
    "            if time.time() - start_time > timeout_sec:\n",
    "                raise TimeoutError(\"parallel_map_qutip is hanging or a worker failed.\")\n",
    "\n",
    " \n",
    "\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "        # return results\n",
    "\n",
    " \n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "        os.environ[\"QUTIP_IN_PARALLEL\"] = \"FALSE\"\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "        raise e\n",
    "\n",
    "\n",
    "try:\n",
    "    # pathos implementation is much more robust - should install if not present\n",
    "    import pathos.multiprocessing as mp\n",
    "except ImportError:\n",
    "    # but default to std library version\n",
    "    print(\n",
    "        \"using std lib version of multiprocessing; consider installing pathos; it's much more robust\"\n",
    "    )\n",
    "    import multiprocessing as mp\n",
    "    \n",
    "\n",
    "\n",
    "def varg_opt(data, axis=None, opt_fun=np.nanargmin):\n",
    "    \"\"\"\n",
    "    Return an index of a (possibly) multi-dimensional array of the element that\n",
    "    optimizes a given function along with the optimal value.\n",
    "    \"\"\"\n",
    "    index = arg_opt(data, axis=axis, opt_fun=opt_fun)\n",
    "    return index, data[index]\n",
    "\n",
    "def parallel_map_adapter(f, iterable):\n",
    "    return parallel_map_qutip(f, list(iterable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2363abe-ee2a-457b-9ad8-220b192a4ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.540282Z",
     "iopub.status.busy": "2025-07-16T18:54:31.540061Z",
     "iopub.status.idle": "2025-07-16T18:54:31.543853Z",
     "shell.execute_reply": "2025-07-16T18:54:31.543358Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.540265Z"
    }
   },
   "outputs": [],
   "source": [
    "def param_map(f, parameters, map_fun=map, dtype=object):\n",
    "\n",
    "    dims_list = [len(i) for i in parameters]\n",
    "    total_dim = np.prod(dims_list)\n",
    "    parameters_prod = tuple(itertools.product(*parameters))\n",
    "\n",
    "    data = np.empty(total_dim, dtype=dtype)\n",
    "    # for i, d in enumerate(map_fun(f, parameters_prod)):\n",
    "    #     data[i] = d\n",
    "    for i, d in enumerate(map_fun(lambda args: f(*args), parameters_prod)):\n",
    "        data[i] = d\n",
    "    print(\"complete param map\")\n",
    "    return np.reshape(data, dims_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899ce2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map_qutip_2(task, values, task_args=tuple(), task_kwargs={}, **kwargs):\n",
    "    os.environ[\"QUTIP_IN_PARALLEL\"] = \"TRUE\"\n",
    "    kw = _default_kwargs()\n",
    "    if \"num_cpus\" in kwargs:\n",
    "        kw[\"num_cpus\"] = kwargs[\"num_cpus\"]\n",
    "\n",
    "    try:\n",
    "        pool = mp.Pool(processes=kw[\"num_cpus\"])\n",
    "        async_res = [\n",
    "            pool.apply_async(\n",
    "                task, (value,) + task_args, task_kwargs\n",
    "            )\n",
    "            for value in values\n",
    "        ]\n",
    "\n",
    "        # Collect results\n",
    "        results = [ar.get() for ar in async_res]\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        start_time = time.time()\n",
    "        timeout_sec = 600  # Increased timeout for complex simulations\n",
    "        while not all([ar.ready() for ar in async_res]):\n",
    "            print(f\"{sum(ar.ready() for ar in async_res)}/{len(async_res)} tasks completed...\")\n",
    "            time.sleep(1)\n",
    "            if time.time() - start_time > timeout_sec:\n",
    "                raise TimeoutError(\"parallel_map_qutip is hanging or a worker failed.\")\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        os.environ[\"QUTIP_IN_PARALLEL\"] = \"FALSE\"\n",
    "        return results\n",
    "\n",
    "    except KeyboardInterrupt as e:\n",
    "        os.environ[\"QUTIP_IN_PARALLEL\"] = \"FALSE\"\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        os.environ[\"QUTIP_IN_PARALLEL\"] = \"FALSE\"\n",
    "        pool.terminate()\n",
    "        pool.join()\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775cce3c-5f05-4087-aac9-f8fefefe9f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:54:31.544685Z",
     "iopub.status.busy": "2025-07-16T18:54:31.544478Z",
     "iopub.status.idle": "2025-07-16T18:54:31.932839Z",
     "shell.execute_reply": "2025-07-16T18:54:31.932048Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.544662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total simulations to run: 100\n",
      "0/100 tasks completed...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#single process\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# fidelity_results = param_map(evolve, [omega_d_array, t_g_array])\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#parallel process\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# fidelity_results = param_map(wrapped_evolve, [omega_d_array, t_g_array], map_fun=parallel_map_qutip)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m fidelity_results \u001b[38;5;241m=\u001b[39m param_map(wrapped_evolve, [omega_d_array, t_g_array], map_fun\u001b[38;5;241m=\u001b[39mparallel_map_qutip)\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mparam_map\u001b[1;34m(f, parameters, map_fun, dtype)\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(total_dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# for i, d in enumerate(map_fun(f, parameters_prod)):\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     data[i] = d\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_fun(\u001b[38;5;28;01mlambda\u001b[39;00m args: f(\u001b[38;5;241m*\u001b[39margs), parameters_prod)):\n\u001b[0;32m     11\u001b[0m     data[i] \u001b[38;5;241m=\u001b[39m d\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete param map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "evals, _ = fluxonium.eigensys(evals_count=levels)\n",
    "omega_d_base = evals[1] - evals[0]\n",
    "\n",
    "omega_d_array = np.linspace(omega_d_base - 0.005, omega_d_base + 0.005, 10)\n",
    "peak_time_noise = 559.5559555955596  # previously determined\n",
    "t_g_array = np.linspace(0.99 * peak_time_noise, 1.01 * peak_time_noise, 10)\n",
    "param_pairs = list(itertools.product(omega_d_array, t_g_array))\n",
    "print(f\"Total simulations to run: {len(param_pairs)}\")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    module=\"qutip.*\"  # Regex pattern to match all warnings from qutip\n",
    ")\n",
    "scq.settings.T1_DEFAULT_WARNING=False\n",
    "\n",
    "try:\n",
    "    # pathos implementation is much more robust - should install if not present\n",
    "    import pathos.multiprocessing as mp\n",
    "except ImportError:\n",
    "    # but default to std library version\n",
    "    print(\n",
    "        \"using std lib version of multiprocessing; consider installing pathos; it's much more robust\"\n",
    "    )\n",
    "    import multiprocessing as mp\n",
    "\n",
    "def _default_kwargs():\n",
    "    return {\"num_cpus\": os.cpu_count() or 1}\n",
    "\n",
    "#single process\n",
    "# fidelity_results = param_map(evolve, [omega_d_array, t_g_array])\n",
    "\n",
    "#parallel process\n",
    "# fidelity_results = param_map(wrapped_evolve, [omega_d_array, t_g_array], map_fun=parallel_map_qutip)\n",
    "\n",
    "fidelity_results = param_map(wrapped_evolve, [omega_d_array, t_g_array], map_fun=parallel_map_qutip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32105e60-3262-44fd-bdac-f57582c9fba3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-07-16T18:54:31.933348Z",
     "iopub.status.idle": "2025-07-16T18:54:31.933578Z",
     "shell.execute_reply": "2025-07-16T18:54:31.933449Z",
     "shell.execute_reply.started": "2025-07-16T18:54:31.933438Z"
    }
   },
   "outputs": [],
   "source": [
    "fidelity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50405065",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e8a7f",
   "metadata": {},
   "source": [
    "## parallel_map from qutip parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd446c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from ipyparallel import Client\n",
    "\n",
    "\n",
    "def parallel_map(task, values, task_args=None, task_kwargs=None,\n",
    "                 client=None, view=None, progress_bar=None,\n",
    "                 show_scheduling=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Call the function ``task`` for each value in ``values`` using a cluster\n",
    "    of IPython engines. The function ``task`` should have the signature\n",
    "    ``task(value, *args, **kwargs)``.\n",
    "\n",
    "    The ``client`` and ``view`` are the IPython.parallel client and\n",
    "    load-balanced view that will be used in the parfor execution. If these\n",
    "    are ``None``, new instances will be created.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    task: a Python function\n",
    "        The function that is to be called for each value in ``task_vec``.\n",
    "\n",
    "    values: array / list\n",
    "        The list or array of values for which the ``task`` function is to be\n",
    "        evaluated.\n",
    "\n",
    "    task_args: list / dictionary\n",
    "        The optional additional argument to the ``task`` function.\n",
    "\n",
    "    task_kwargs: list / dictionary\n",
    "        The optional additional keyword argument to the ``task`` function.\n",
    "\n",
    "    client: IPython.parallel.Client\n",
    "        The IPython.parallel Client instance that will be used in the\n",
    "        parfor execution.\n",
    "\n",
    "    view: a IPython.parallel.Client view\n",
    "        The view that is to be used in scheduling the tasks on the IPython\n",
    "        cluster. Preferably a load-balanced view, which is obtained from the\n",
    "        IPython.parallel.Client instance client by calling,\n",
    "        view = client.load_balanced_view().\n",
    "\n",
    "    show_scheduling: bool {False, True}, default False\n",
    "        Display a graph showing how the tasks (the evaluation of ``task`` for\n",
    "        for the value in ``task_vec1``) was scheduled on the IPython engine\n",
    "        cluster.\n",
    "\n",
    "    show_progressbar: bool {False, True}, default False\n",
    "        Display a HTML-based progress bar during the execution of the parfor\n",
    "        loop.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    result : list\n",
    "        The result list contains the value of\n",
    "        ``task(value, task_args, task_kwargs)`` for each\n",
    "        value in ``values``.\n",
    "\n",
    "    \"\"\"\n",
    "    submitted = datetime.datetime.now()\n",
    "\n",
    "    if task_args is None:\n",
    "        task_args = tuple()\n",
    "\n",
    "    if task_kwargs is None:\n",
    "        task_kwargs = {}\n",
    "\n",
    "    if client is None:\n",
    "        client = Client()\n",
    "\n",
    "        # make sure qutip is available at engines\n",
    "        dview = client[:]\n",
    "        dview.block = True\n",
    "        dview.execute(\"from qutip import *\")\n",
    "\n",
    "    if view is None:\n",
    "        view = client.load_balanced_view()\n",
    "\n",
    "    ar_list = [view.apply_async(task, value, *task_args, **task_kwargs)\n",
    "               for value in values]\n",
    "\n",
    "    if progress_bar is None:\n",
    "        view.wait(ar_list)\n",
    "    else:\n",
    "        if progress_bar is True:\n",
    "            progress_bar = HTMLProgressBar()\n",
    "\n",
    "        n = len(ar_list)\n",
    "        progress_bar.start(n)\n",
    "        while True:\n",
    "            n_finished = sum([ar.progress for ar in ar_list])\n",
    "            progress_bar.update(n_finished)\n",
    "\n",
    "            if view.wait(ar_list, timeout=0.5):\n",
    "                progress_bar.update(n)\n",
    "                break\n",
    "        progress_bar.finished()\n",
    "\n",
    "    if show_scheduling:\n",
    "        metadata = [[ar.engine_id,\n",
    "                     (ar.started - submitted).total_seconds(),\n",
    "                     (ar.completed - submitted).total_seconds()]\n",
    "                    for ar in ar_list]\n",
    "        _visualize_parfor_data(metadata)\n",
    "\n",
    "    return [ar.get() for ar in ar_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31afd6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection file: ~\\.ipython\\profile_default\\security\\ipcontroller-client.json\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Connection file '~\\\\.ipython\\\\profile_default\\\\security\\\\ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel_map(\n\u001b[0;32m      2\u001b[0m     task\u001b[38;5;241m=\u001b[39mwrapped_evolve,\n\u001b[0;32m      3\u001b[0m     values\u001b[38;5;241m=\u001b[39mparam_pairs,\n\u001b[0;32m      4\u001b[0m     progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n",
      "Cell \u001b[1;32mIn[24], line 69\u001b[0m, in \u001b[0;36mparallel_map\u001b[1;34m(task, values, task_args, task_kwargs, client, view, progress_bar, show_scheduling, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m     task_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# make sure qutip is available at engines\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     dview \u001b[38;5;241m=\u001b[39m client[:]\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\ipyparallel\\client\\client.py:456\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, connection_info, url_file, profile, profile_dir, ipython_dir, context, debug, sshserver, sshkey, password, paramiko, timeout, cluster_id, cluster, **extra_args)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(connection_file):\n\u001b[0;32m    455\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshort\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m, no_file_msg])\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(connection_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    459\u001b[0m     connection_info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mOSError\u001b[0m: Connection file '~\\\\.ipython\\\\profile_default\\\\security\\\\ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running."
     ]
    }
   ],
   "source": [
    "results = parallel_map(\n",
    "    task=wrapped_evolve,\n",
    "    values=param_pairs,\n",
    "    progress_bar=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
